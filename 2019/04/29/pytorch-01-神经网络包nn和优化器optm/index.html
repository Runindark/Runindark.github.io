<!DOCTYPE html>
<html>
  
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  <meta name="author" content="Runindark">
  
  
  <title>神经网络包nn和优化器optm | Cat&#39;s blog</title>

  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  
    <meta name="keywords" content="Hexo, Theme-AD">
  

  
  <meta name="description" content="pytorm中文手册pytormAPIpytorch官网pytorchCDN加速中文手册">

  

  
    <script src="//cdn.jsdelivr.net/npm/leancloud-storage@3.11.1/dist/av-min.js" async></script>
  

  
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML" async></script>
  

  
    <script src="//unpkg.com/valine/dist/Valine.min.js" async></script>
  

  

  <script>
  // theme-ad's config script
  // it can be used in every script
  
  window.AD_CONFIG = {
    leancloud: {"appid":"OCuFc66d0cFinCcq4woaFKKx-gzGzoHsz","appkey":"Al6ba44bHAyyU7EbkpugUs1L","comment":true,"count":true},
    welcome: {"enable":true,"interval":30},
    start_time: "2018-02-10",
    passwords: ["efe07af7441da2b69c4a41e42e73be4db47f66010a56900788a458354a7373ec", ],
    is_post: true,
    lock: false,
    author: "Runindark",
    share: {"twitter":true,"facebook":true,"weibo":true,"qq":true,"wechat":true},
    mathjax: true,
    page_type: "",
    root: "/"
  };
</script>

  <script src="/vendor/sha256.min.js"></script>
<script src="/js/auth.js"></script>
<script src="/js/index.js"></script>
<script src="/vendor/qrcode.min.js"></script>

  
    <link rel="icon" href="/images/favicon.ico">
    <link rel="apple-touch-icon" href="/images/touch-icon.png">
  

  <link href="//netdna.bootstrapcdn.com/font-awesome/4.7.0/css/font-awesome.min.css" rel="stylesheet">

  <link rel="stylesheet" href="/css/index.css">
<link rel="stylesheet" href="/styles/components/highlight/highlight.css">

  
</head>
  <body>
    <header class="site-header">
  <div class="site-header-brand">
    
      <span class="site-header-brand-title">
        <a href="/">Runidark</a>
      </span>
    
    
      <span class="site-header-brand-motto"> | With Thinking All</span>
    
  </div>
  <div class="site-header-right">
    <nav class="site-header-navigation">
      
        <a href="/" target="_self">首页</a>
      
        <a href="/archives/" target="_self">归档</a>
      
        <a href="/tags/" target="_self">标签</a>
      
        <a href="/categories/" target="_self">分类</a>
      
        <a href="/friends/" target="_self">友链</a>
      
        <a href="/about/" target="_self">关于</a>
      
    </nav>
    <div class="site-header-btn">
      
        <a href="https://github.com/Runindark?tab=repositories" target="_blank" id="site-github">
          <i class="fa fa-github-alt"></i>
        </a>
      
      <a href="javascript:void(0);" id="site-search">
        <i class="fa fa-search"></i>
      </a>
      <a href="javascript:void(0);" id="site-nav-btn">
        <i class="fa fa-ellipsis-v"></i>
      </a>
    </div>
  </div>
</header>
<nav class="table-content" id="site-nav">
  <div class="table-content-title">
    <span>导航</span>
  </div>
  <div class="table-content-main">
    <ol class="toc">
      
        <li class="toc-item">
          <a href="/" target="_self">
            首页
          </a>
        </li>
      
        <li class="toc-item">
          <a href="/archives/" target="_self">
            归档
          </a>
        </li>
      
        <li class="toc-item">
          <a href="/tags/" target="_self">
            标签
          </a>
        </li>
      
        <li class="toc-item">
          <a href="/categories/" target="_self">
            分类
          </a>
        </li>
      
        <li class="toc-item">
          <a href="/friends/" target="_self">
            友链
          </a>
        </li>
      
        <li class="toc-item">
          <a href="/about/" target="_self">
            关于
          </a>
        </li>
      
    </ol>
  </div>
</nav>
<div id="site-process"></div>
    <main>
      
  <div class="passage">
  <div class="passage-meta">
    <span>
      <i class="fa fa-calendar"></i>2019-04-29
    </span>
    
    
      <span>
        | <i class="fa fa-unlock-alt"></i>UNLOCK
      </span>
    
  </div>
  <h1 class="passage-title">
    神经网络包nn和优化器optm
  </h1>
  
  <article class="passage-article">
    <p></p>
<the rest="" of="" contents="" |="" 余下全文="">

<h2 id="相关包引入"><a href="#相关包引入" class="headerlink" title="相关包引入"></a>相关包引入</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br></pre></td></tr></table></figure>
<ol>
<li>torch.nn是专门为神经网络设计的模块化接口,n构建于 Autograd之上，可用来定义和运行神经网络。</li>
<li>nn.functional，这个包中包含了神经网络中使用的一些常用函数，这些函数的特点是，不具有可学习的参数(如ReLU，pool，DropOut等)，这些函数可以放在构造函数中，也可以不放，但是这里建议不放</li>
</ol>
<h2 id="定义一个神经网络"><a href="#定义一个神经网络" class="headerlink" title="定义一个神经网络"></a>定义一个神经网络</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个网络</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">		super(Net, self).__init__()</span><br><span class="line">		<span class="comment"># 卷积层 '1'表示输入图片为单通道, '6'表示输出通道数，'3'表示卷积核为3*3</span></span><br><span class="line">		self.conv1 = nn.Conv2d(<span class="number">1</span>,<span class="number">6</span>,<span class="number">3</span>)</span><br><span class="line">		<span class="comment"># 线性层，输入1350个特征，输出10个特征</span></span><br><span class="line">		self.fc1 = nn.Linear(<span class="number">1350</span>,<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">		print(x.size())</span><br><span class="line">		<span class="comment"># 结果：[1, 1, 32, 32]</span></span><br><span class="line">		<span class="comment"># 卷积 -&gt; 激活 -&gt; 池化</span></span><br><span class="line">		<span class="comment"># 卷积的尺寸计算公式后续??</span></span><br><span class="line">		x = F.relu(x)</span><br><span class="line">		print(x.size())</span><br><span class="line">		<span class="comment"># 结果：[1, 6, 30, 30]</span></span><br><span class="line">		x = F.max_pool2d(x,(<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line">		x = F.relu(x)</span><br><span class="line">		print(x.size())</span><br><span class="line">		<span class="comment"># 结果：[1, 6, 15, 15]</span></span><br><span class="line">		x = x.view(x.size()[<span class="number">0</span>],<span class="number">-1</span>)</span><br><span class="line">		<span class="comment"># reshape，‘-1’表示自适应</span></span><br><span class="line">        <span class="comment">#这里做的就是压扁的操作 就是把后面的[1, 6, 15, 15]压扁，变为 [1, 1350]</span></span><br><span class="line">		print(x.size())</span><br><span class="line">		x = self.fcl(x)</span><br><span class="line">		<span class="keyword">return</span> x ;</span><br><span class="line">net = Net()</span><br><span class="line">print(net)</span><br></pre></td></tr></table></figure>
<p>结果如下</p>
<blockquote>
<p>Net(<br>  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))<br>  (fc1): Linear(in_features=1350, out_features=10, bias=True)<br>)</p>
</blockquote>
<h2 id="返回学习参数"><a href="#返回学习参数" class="headerlink" title="返回学习参数"></a>返回学习参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> parameter <span class="keyword">in</span> net.parameters():</span><br><span class="line">	print(parameter)</span><br></pre></td></tr></table></figure>
<h2 id="返回可学习的参数及名称"><a href="#返回可学习的参数及名称" class="headerlink" title="返回可学习的参数及名称"></a>返回可学习的参数及名称</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> name,parameters <span class="keyword">in</span> net.named_parameters():</span><br><span class="line">    print(name,<span class="string">':'</span>,parameters.size())</span><br></pre></td></tr></table></figure>
<h2 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h2><ol>
<li>在反向传播前，先要将所有参数的梯度清零</li>
<li>torch.nn只支持mini-batches，不支持一次只输入一个样本，即一次必须是一个batch。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net.zero_grad() </span><br><span class="line">out.backward(torch.ones(<span class="number">1</span>,<span class="number">10</span>))</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">y = torch.arange(<span class="number">0</span>,<span class="number">10</span>).view(<span class="number">1</span>,<span class="number">10</span>).float()</span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line">loss = criterion(out, y)</span><br><span class="line"><span class="comment">#loss是个scalar，我们可以直接用item获取到他的python类型的数值</span></span><br><span class="line">print(loss.item())</span><br></pre></td></tr></table></figure>
<h2 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h2><p>在反向传播计算完所有参数的梯度后，还需要使用优化方法来更新网络的权重和参数，例如随机梯度下降法(SGD)的更新策略如下：</p>
<p>weight = weight - learning_rate * gradient</p>
<p>在torch.optim中实现大多数的优化方法，例如RMSProp、Adam、SGD等，下面我们使用SGD做个简单的样例</p>
<h3 id="导optim包-amp-amp-代码"><a href="#导optim包-amp-amp-代码" class="headerlink" title="导optim包 &amp;&amp; 代码"></a>导optim包 &amp;&amp; 代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">out = net(input) <span class="comment"># 这里调用的时候会打印出我们在forword函数中打印的x的大小</span></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line">loss = criterion(out, y)</span><br><span class="line"><span class="comment">#新建一个优化器，SGD只需要要调整的参数和学习率</span></span><br><span class="line">optimizer = torch.optim.SGD(net.parameters(), lr = <span class="number">0.01</span>)</span><br><span class="line"><span class="comment"># 先梯度清零(与net.zero_grad()效果一样)</span></span><br><span class="line">optimizer.zero_grad() </span><br><span class="line">loss.backward()</span><br><span class="line"></span><br><span class="line"><span class="comment">#更新参数</span></span><br><span class="line">optimizer.step()</span><br></pre></td></tr></table></figure></the>
  </article>
  <aside class="table-content" id="site-toc">
  <div class="table-content-title">
    <i class="fa fa-arrow-right fa-lg" id="site-toc-hide-btn"></i>
    <span>目录</span>
  </div>
  <div class="table-content-main">
    <ol class="toc"><li class="toc-item toc-level-2"><a class="toc-link" href="#相关包引入"><span class="toc-text">相关包引入</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#定义一个神经网络"><span class="toc-text">定义一个神经网络</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#返回学习参数"><span class="toc-text">返回学习参数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#返回可学习的参数及名称"><span class="toc-text">返回可学习的参数及名称</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#反向传播"><span class="toc-text">反向传播</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#损失函数"><span class="toc-text">损失函数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#优化器"><span class="toc-text">优化器</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#导optim包-amp-amp-代码"><span class="toc-text">导optim包 &amp;&amp; 代码</span></a></li></ol></li></ol>
  </div>
</aside>
  
    <aside class="passage-copyright">
      <div>本文作者: Runindark</div>
      
        <div>
          原文链接: 
          <a href="" target="_blank">http://runindark.com/2019/04/29/pytorch-01-神经网络包nn和优化器optm/</a>
        </div>
      
      <div>
        
      </div>
    </aside>
  
  
</div>

    </main>
    
      
<div class="site-comment-contanier" data-plateform="leancloud">
  
    <p id="site-comment-info">
      <i class="fa fa-spinner fa-spin"></i> 评论加载中
    </p>
    <div id="site-comment"></div>
  
</div>
    
    <div class="site-footer-wrapper">
  <footer class="site-footer">
    
    <div class="site-footer-info">
      <i class="fa fa-clock-o"></i> 本站已稳定运行<span id="site-time"></span>
    </div>
    
      <div class="site-footer-info">
        <i class="fa fa-paw"></i> 您是本站第 <span id="site-count"></span> 位访客
      </div>
    
    
    <div class="site-footer-info">
      <i class="fa fa-copyright"></i> 
      2019 <a href="https://github.com/dongyuanxin/theme-ad/" target="_blank">Theme-AD</a>.
      Created by <a href="https://godbmw.com/" target="_blank">GodBMW</a>.
      All rights reserved.
    </div>
  </footer>
</div>
    <div id="site-layer" style="display:none;">
  <div class="site-layer-content">
    <div class="site-layer-header">
      <span class="site-layer-header-title" id="site-layer-title"></span>
      <i class="fa fa-close" id="site-layer-close"></i>
    </div>
    <div class="site-layer-body" id="site-layer-container">
      <div class="site-layer-input" id="site-layer-search" style="display: none;">
        <input type="text">
        <i class="fa fa-search"></i>
      </div>
      
        <div class="site-layer-reward" id="site-layer-reward" style="display: none;">
          
            <div>
              <img src="/images/wechat.png" alt="WeChat">
              
                <p>WeChat</p>
              
            </div>
          
            <div>
              <img src="/images/alipay.png" alt="AliPay">
              
                <p>AliPay</p>
              
            </div>
          
        </div>
      
      <div id="site-layer-welcome" style="display:none;"></div>
    </div>
  </div>
</div>
    

<div class="bottom-bar">
  <div class="bottom-bar-left">
    <a href="/2019/04/29/pytorch-02-数据的加载和预处理/" data-enable="true">
      <i class="fa fa-arrow-left"></i>
    </a>
    <a href="/2019/04/19/test/" data-enable="true">
      <i class="fa fa-arrow-right"></i>
    </a>
  </div>
  <div class="bottom-bar-right">
    <a href="javascript:void(0);" data-enable="true" id="site-toc-show-btn">
      <i class="fa fa-bars"></i>
    </a>
    
      <a href="#site-comment" data-enable="true">
        <i class="fa fa-commenting"></i>
      </a>
    
    <a href="javascript:void(0);" id="site-toggle-share-btn">
      <i class="fa fa-share-alt"></i>
    </a>
    
      <a href="javascript:void(0);" id="site-reward">
        <i class="fa fa-thumbs-up"></i>
      </a>
    
    <a href="javascript:void(0);" id="back-top-btn">
      <i class="fa fa-chevron-up"></i>
    </a>
  </div>
</div>
    <div id="share-btn">
  
    <a id="share-btn-twitter" href="javascript:void(0);" target="_blank">
      <i class="fa fa-twitter"></i>
    </a>
  
  
    <a id="share-btn-facebook" href="javascript:void(0);" target="_blank">
      <i class="fa fa-facebook"></i>
    </a>
  
  
    <a id="share-btn-weibo" href="javascript:void(0);" target="_blank">
      <i class="fa fa-weibo"></i>
    </a>
  
  
    <a id="share-btn-qq" href="javascript:void(0);" target="_blank">
      <i class="fa fa-qq"></i>
    </a>
  
  
    <a id="share-btn-wechat" href="javascript:void(0);" target="_blank">
      <i class="fa fa-wechat"></i>
    </a>
  
</div>
    





    
  </body>
</html>