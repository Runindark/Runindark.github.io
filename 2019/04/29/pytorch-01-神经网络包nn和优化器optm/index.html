<!DOCTYPE html>
<html lang="en">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <title>
    神经网络包nn和优化器optm |
    
    Cat&#39;s blog</title>
  
    <link rel="shortcut icon" href="/favicon.ico">
  
  <link rel="stylesheet" href="/css/style.css">
  
    <link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">
  
  <script src="/js/pace.min.js"></script>
</head>
</html>
<body>
<main class="content">
  <section class="outer">
  

<article id="post-pytorch-01-神经网络包nn和优化器optm" class="article article-type-post" itemscope="" itemprop="blogPost" data-scroll-reveal="">
  
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      神经网络包nn和优化器optm
    </h1>
  
  




      </header>
    

    
      <div class="article-meta">
        <a href="/2019/04/29/pytorch-01-神经网络包nn和优化器optm/" class="article-date">
  <time datetime="2019-04-29T07:31:26.960Z" itemprop="datePublished">2019-04-29</time>
</a>
        
      </div>
    

    
      
    <div class="tocbot"></div>





    

    <div class="article-entry" itemprop="articleBody">
      


      

      
        <p><excerpt in="" index="" |="" 首页摘要=""><br><a href="https://github.com/zergtant/pytorch-handbook" target="_blank" rel="noopener">pytorm中文手册</a><br><a href="https://pytorch-cn.readthedocs.io/zh/latest/torchvision/torchvision-datasets/" target="_blank" rel="noopener">pytormAPI</a><br><a href="https://pytorch.org/" target="_blank" rel="noopener">pytorch官网</a><br><a href="https://zjcqoo.github.io/-----https://github.com/zergtant/pytorch-handbook" target="_blank" rel="noopener">pytorchCDN加速中文手册</a><br><a id="more"></a></excerpt></p>
<the rest="" of="" contents="" |="" 余下全文="">

<h2 id="相关包引入"><a href="#相关包引入" class="headerlink" title="相关包引入"></a>相关包引入</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br></pre></td></tr></table></figure>
<ol>
<li>torch.nn是专门为神经网络设计的模块化接口,n构建于 Autograd之上，可用来定义和运行神经网络。</li>
<li>nn.functional，这个包中包含了神经网络中使用的一些常用函数，这些函数的特点是，不具有可学习的参数(如ReLU，pool，DropOut等)，这些函数可以放在构造函数中，也可以不放，但是这里建议不放</li>
</ol>
<h2 id="定义一个神经网络"><a href="#定义一个神经网络" class="headerlink" title="定义一个神经网络"></a>定义一个神经网络</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line"><span class="comment"># 定义一个网络</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Net</span><span class="params">(nn.Module)</span>:</span></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">		super(Net, self).__init__()</span><br><span class="line">		<span class="comment"># 卷积层 '1'表示输入图片为单通道, '6'表示输出通道数，'3'表示卷积核为3*3</span></span><br><span class="line">		self.conv1 = nn.Conv2d(<span class="number">1</span>,<span class="number">6</span>,<span class="number">3</span>)</span><br><span class="line">		<span class="comment"># 线性层，输入1350个特征，输出10个特征</span></span><br><span class="line">		self.fc1 = nn.Linear(<span class="number">1350</span>,<span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></span><br><span class="line">		print(x.size())</span><br><span class="line">		<span class="comment"># 结果：[1, 1, 32, 32]</span></span><br><span class="line">		<span class="comment"># 卷积 -&gt; 激活 -&gt; 池化</span></span><br><span class="line">		<span class="comment"># 卷积的尺寸计算公式后续??</span></span><br><span class="line">		x = F.relu(x)</span><br><span class="line">		print(x.size())</span><br><span class="line">		<span class="comment"># 结果：[1, 6, 30, 30]</span></span><br><span class="line">		x = F.max_pool2d(x,(<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line">		x = F.relu(x)</span><br><span class="line">		print(x.size())</span><br><span class="line">		<span class="comment"># 结果：[1, 6, 15, 15]</span></span><br><span class="line">		x = x.view(x.size()[<span class="number">0</span>],<span class="number">-1</span>)</span><br><span class="line">		<span class="comment"># reshape，‘-1’表示自适应</span></span><br><span class="line">        <span class="comment">#这里做的就是压扁的操作 就是把后面的[1, 6, 15, 15]压扁，变为 [1, 1350]</span></span><br><span class="line">		print(x.size())</span><br><span class="line">		x = self.fcl(x)</span><br><span class="line">		<span class="keyword">return</span> x ;</span><br><span class="line">net = Net()</span><br><span class="line">print(net)</span><br></pre></td></tr></table></figure>
<p>结果如下</p>
<blockquote>
<p>Net(<br>  (conv1): Conv2d(1, 6, kernel_size=(3, 3), stride=(1, 1))<br>  (fc1): Linear(in_features=1350, out_features=10, bias=True)<br>)</p>
</blockquote>
<h2 id="返回学习参数"><a href="#返回学习参数" class="headerlink" title="返回学习参数"></a>返回学习参数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> parameter <span class="keyword">in</span> net.parameters():</span><br><span class="line">	print(parameter)</span><br></pre></td></tr></table></figure>
<h2 id="返回可学习的参数及名称"><a href="#返回可学习的参数及名称" class="headerlink" title="返回可学习的参数及名称"></a>返回可学习的参数及名称</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> name,parameters <span class="keyword">in</span> net.named_parameters():</span><br><span class="line">    print(name,<span class="string">':'</span>,parameters.size())</span><br></pre></td></tr></table></figure>
<h2 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h2><ol>
<li>在反向传播前，先要将所有参数的梯度清零</li>
<li>torch.nn只支持mini-batches，不支持一次只输入一个样本，即一次必须是一个batch。<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">net.zero_grad() </span><br><span class="line">out.backward(torch.ones(<span class="number">1</span>,<span class="number">10</span>))</span><br></pre></td></tr></table></figure>
</li>
</ol>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">y = torch.arange(<span class="number">0</span>,<span class="number">10</span>).view(<span class="number">1</span>,<span class="number">10</span>).float()</span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line">loss = criterion(out, y)</span><br><span class="line"><span class="comment">#loss是个scalar，我们可以直接用item获取到他的python类型的数值</span></span><br><span class="line">print(loss.item())</span><br></pre></td></tr></table></figure>
<h2 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h2><p>在反向传播计算完所有参数的梯度后，还需要使用优化方法来更新网络的权重和参数，例如随机梯度下降法(SGD)的更新策略如下：</p>
<p>weight = weight - learning_rate * gradient</p>
<p>在torch.optim中实现大多数的优化方法，例如RMSProp、Adam、SGD等，下面我们使用SGD做个简单的样例</p>
<h3 id="导optim包-amp-amp-代码"><a href="#导optim包-amp-amp-代码" class="headerlink" title="导optim包 &amp;&amp; 代码"></a>导optim包 &amp;&amp; 代码</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch.optim</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">out = net(input) <span class="comment"># 这里调用的时候会打印出我们在forword函数中打印的x的大小</span></span><br><span class="line">criterion = nn.MSELoss()</span><br><span class="line">loss = criterion(out, y)</span><br><span class="line"><span class="comment">#新建一个优化器，SGD只需要要调整的参数和学习率</span></span><br><span class="line">optimizer = torch.optim.SGD(net.parameters(), lr = <span class="number">0.01</span>)</span><br><span class="line"><span class="comment"># 先梯度清零(与net.zero_grad()效果一样)</span></span><br><span class="line">optimizer.zero_grad() </span><br><span class="line">loss.backward()</span><br><span class="line"></span><br><span class="line"><span class="comment">#更新参数</span></span><br><span class="line">optimizer.step()</span><br></pre></td></tr></table></figure></the>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://runindark.com/2019/04/29/pytorch-01-神经网络包nn和优化器optm/" data-id="ckbyf1aah000rkkv1ce7f76u3" class="article-share-link">Share</a>
      
    </footer>

  </div>

  
    
  <nav class="article-nav">
    
      <a href="/2019/04/29/pytorch-02-数据的加载和预处理/" class="article-nav-link">
        <strong class="article-nav-caption">Newer posts</strong>
        <div class="article-nav-title">
          
            数据加载和预处理
          
        </div>
      </a>
    
    
      <a href="/2019/04/19/test/" class="article-nav-link">
        <strong class="article-nav-caption">Olde posts</strong>
        <div class="article-nav-title">Pytorch</div>
      </a>
    
  </nav>


  

  
    
  

</article>



</section>
  <footer class="footer">
  <div class="outer">
    <div class="float-right">
      <ul class="list-inline">
  
    <li><i class="fe fe-smile-alt"></i> <span id="busuanzi_value_site_uv"></span></li>
  
</ul>
    </div>
    <ul class="list-inline">
      <li>&copy; 2020 Cat&#39;s blog</li>
      <li>Powered by <a href="http://hexo.io/" target="_blank">Hexo</a></li>
      <li>Theme  <a href="https://github.com/zhwangart/hexo-theme-ocean">Ocean</a></li>
    </ul>
  </div>
</footer>

</main>

<aside class="sidebar sidebar-specter">
  
    <button class="navbar-toggle"></button>
<nav class="navbar">
  
    <div class="logo">
      <a href="/"><img src="/images/hexo.svg" alt="Cat&#39;s blog"></a>
    </div>
  
  <ul class="nav nav-main">
    
      <li class="nav-item">
        <a class="nav-item-link" href="/">Home</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/archives">Archives</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/gallery">Gallery</a>
      </li>
    
      <li class="nav-item">
        <a class="nav-item-link" href="/about">About</a>
      </li>
    
    <li class="nav-item">
      <a class="nav-item-link nav-item-search" title="Search">
        <i class="fe fe-search"></i>
        Search
      </a>
    </li>
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      <div class="totop" id="totop">
  <i class="fe fe-rocket"></i>
</div>
    </li>
    <li class="nav-item">
      
        <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
          <i class="fe fe-feed"></i>
        </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>
  </aside>
  <script src="/js/jquery-2.0.3.min.js"></script>
<script src="/js/jquery.justifiedGallery.min.js"></script>
<script src="/js/lazyload.min.js"></script>
<script src="/js/busuanzi-2.3.pure.min.js"></script>

  <script src="/fancybox/jquery.fancybox.min.js"></script>



  <script src="/js/tocbot.min.js"></script>
  <script>
    // Tocbot_v4.7.0  http://tscanlin.github.io/tocbot/
    tocbot.init({
      tocSelector: '.tocbot',
      contentSelector: '.article-entry',
      headingSelector: 'h1, h2, h3, h4, h5, h6',
      hasInnerContainers: true,
      scrollSmooth: true,
      positionFixedSelector: '.tocbot',
      positionFixedClass: 'is-position-fixed',
      fixedSidebarOffset: 'auto',
    });
  </script>


<script src="/js/ocean.js"></script>

</body>
</html>